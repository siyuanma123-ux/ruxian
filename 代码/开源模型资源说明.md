# 开源乳腺癌诊断模型资源说明

本文档列出了可用于对比诊断的开源预训练模型资源。

## ⚠️ 重要提示

1. **这些模型大多使用ImageNet预训练权重，并非专门为医学影像训练**
2. **结果仅供参考，不能用于实际临床诊断**
3. **建议使用专门在医学影像数据集上训练的模型进行对比**

---

## 已集成的Baseline模型

### 1. ResNet50 (ImageNet预训练)
- **来源**: torchvision
- **预训练数据**: ImageNet
- **特点**: 经典CNN架构，通用性强
- **状态**: ✅ 已集成到对比脚本

### 2. EfficientNet-B0 (ImageNet预训练)
- **来源**: torchvision
- **预训练数据**: ImageNet
- **特点**: 高效的网络架构，参数量少
- **状态**: ✅ 已集成到对比脚本

### 3. Vision Transformer (ViT)
- **来源**: timm库（需要安装）
- **预训练数据**: ImageNet
- **特点**: Transformer架构，适合大规模数据
- **状态**: ⚠️ 需要安装timm库，否则fallback到ResNet

---

## 可用的开源医学影像模型

### 1. MV-Swin-T (多视图Swin Transformer)
- **GitHub**: https://github.com/prithuls/MV-Swin-T
- **论文**: https://arxiv.org/abs/2402.16298
- **特点**: 专门为乳腺X光片分类设计，使用多视图信息
- **数据集**: CBIS-DDSM, Vin-Dr Mammo
- **使用方法**: 
  ```bash
  git clone https://github.com/prithuls/MV-Swin-T
  # 按照README安装依赖和下载预训练权重
  ```

### 2. End-to-end All Convolutional Design
- **GitHub**: https://github.com/lishen/end2end-all-conv
- **论文**: https://arxiv.org/abs/1711.05775
- **特点**: 端到端全卷积网络，用于整体图像诊断
- **数据集**: DDSM, INbreast
- **使用方法**: 
  ```bash
  git clone https://github.com/lishen/end2end-all-conv
  # 按照README安装依赖
  ```

### 3. AUNet (注意力引导密集上采样网络)
- **论文**: https://arxiv.org/abs/1810.10151
- **特点**: 用于全乳腺X光片中的肿块精确分割
- **性能**: CBIS-DDSM上Dice=81.8%, INbreast上Dice=79.1%
- **状态**: 需要查找代码仓库

### 4. EMT-NET (多任务学习)
- **论文**: https://arxiv.org/abs/2201.04795
- **特点**: 同时进行分类和分割
- **性能**: 准确率88.6%, 敏感性94.1%, 特异性85.3%
- **数据集**: 1,511张乳腺超声图像
- **状态**: 需要查找代码仓库

---

## 医学影像预训练模型库

### 1. MONAI Model Zoo
- **网站**: https://monai.io/
- **特点**: 专门为医学影像设计的深度学习框架
- **预训练模型**: 包含多种医学影像任务的预训练模型
- **安装**: 
  ```bash
  pip install monai
  ```

### 2. MedicalNet (3D医学影像)
- **GitHub**: https://github.com/Tencent/MedicalNet
- **特点**: 3D医学影像预训练模型
- **适用**: CT, MRI等3D数据
- **注意**: 主要针对3D数据，X光片是2D

### 3. RadImageNet
- **网站**: https://www.radimagenet.com/
- **特点**: 大规模医学影像预训练模型
- **数据**: 140万张医学影像
- **适用**: 多种医学影像任务

---

## 如何使用这些模型进行对比

### 方法1: 使用已集成的Baseline模型

直接运行对比脚本：
```bash
cd 代码
python3 compare_with_baseline_models.py \
    --mammo_dir "../钼靶报告" \
    --output_dir "../未命名文件夹 2"
```

### 方法2: 集成新的开源模型

1. **下载模型代码和权重**
   ```bash
   git clone <model_repo_url>
   cd <model_repo>
   # 按照README下载预训练权重
   ```

2. **修改对比脚本**
   在 `compare_with_baseline_models.py` 中添加新的模型类：
   ```python
   class NewModel(nn.Module):
       def __init__(self, num_classes=4):
           # 加载模型
           pass
       
       def forward(self, x):
           # 前向传播
           return logits
   ```

3. **添加到模型字典**
   ```python
   models_dict["新模型名称"] = NewModel(num_classes=4).to(device)
   ```

### 方法3: 使用MONAI模型

```python
import monai
from monai.networks.nets import DenseNet121

# 加载预训练的DenseNet121
model = DenseNet121(
    spatial_dims=2,
    in_channels=1,
    out_channels=4,
    pretrained=True  # 如果有医学影像预训练权重
)
```

---

## 模型对比建议

### 1. 选择合适的对比模型
- ✅ 优先选择在医学影像数据集上训练的模型
- ✅ 选择在CBIS-DDSM、INbreast等公开数据集上验证的模型
- ⚠️ ImageNet预训练模型仅作为baseline参考

### 2. 对比指标
- **分类准确率**: 各类别的预测准确率
- **置信度**: 模型对预测的置信程度
- **一致性**: 不同模型预测结果的一致性
- **概率分布**: 各类别的概率分布对比

### 3. 结果解读
- 如果多个模型预测一致，结果更可靠
- 如果模型预测差异大，需要进一步分析
- 注意模型的置信度，低置信度结果不可靠

---

## 注意事项

1. **数据格式**: 确保输入数据格式与模型要求一致
2. **预处理**: 不同模型可能需要不同的预处理方式
3. **类别映射**: 注意不同模型的类别定义可能不同
4. **性能**: ImageNet预训练模型在医学影像上性能可能较差
5. **版权**: 使用开源模型时注意遵守许可证要求

---

## 推荐资源

### 数据集
- **CBIS-DDSM**: https://www.cancerimagingarchive.net/collection/cbis-ddsm/
- **INbreast**: https://www.kaggle.com/datasets/ramanathansp20/inbreast-dataset
- **VinDr-Mammo**: https://vindr.ai/datasets/mammo

### 论文
- Deep Learning for Breast Cancer Detection: A Survey
- Transfer Learning for Medical Image Analysis: A Survey

### 工具
- **MONAI**: 医学影像深度学习框架
- **timm**: PyTorch图像模型库
- **torchvision**: PyTorch官方视觉模型库

---

## 更新日志

- 2025-11-14: 创建文档，集成ResNet50和EfficientNet baseline模型


